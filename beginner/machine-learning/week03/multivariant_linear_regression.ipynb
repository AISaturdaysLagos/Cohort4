{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  <center>Multivariant Linear Regression from scratch.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will be using is a ex1data2.txt file which contains a list of bedroom sizes, number of bedrooms and their corresponding price of the house.\n",
    "\n",
    "The values on the <strong>first column</strong> contains the <strong>bedroom sizes</strong>, the values of the <strong>second column</strong> contains the <strong>number of bedrooms</strong> and values on the <strong>third column</strong> contains the corresponding <strong>price</strong> of the house in Naira.\n",
    "\n",
    "<strong>Objective</strong>: To build a multivariate linear regression model and the optimization technique to generate a model that will predict reasonable estimate of a house price when it is supplied the customers desired room size and number of rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "column_names = [\"size\",\"bedroom\",\"price\"]\n",
    "data = pd.read_csv('data/ex1data2.txt', names = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data shape: {}, column size: {}, row size: {}' \\\n",
    "      .format(data.shape, data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Summary\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation \n",
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to visualize your data before building a model. The aim of data visualization is to give you an insight on the problem. We will be using matplotlib and seaborn libracy for visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['size'].plot(kind='hist',figsize=(8,8), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bedroom'].plot(kind='hist',figsize=(8,8), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the data to see how they correlate.\n",
    "plt.scatter(data.loc[:,'size'], data['price'], s=32, marker='o')\n",
    "plt.xlabel(\"Room Size\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"ROOM SIZE VS PRICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.loc[:,'bedroom'], data['price'], s=32, marker='x')\n",
    "plt.xlabel(\"Number of Bedroom\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"NUMBER OF ROOMS VS PRICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 47 training examples and two independent variable `x` on the first and second column and one dependent variable `y` on the third column\n",
    "\n",
    "**Recall:**\n",
    "- Our untrained model is given by: ![title](img/model.gif)\n",
    "    \n",
    "- Which you can also be written as ![title](img/model2.gif)\n",
    "\n",
    "where:\n",
    "- `y` is the ground truth or output\n",
    "- `x` is the input values\n",
    "- `theta` is the <strong>weight or learnable parameters</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacuse we have three coefficient of `theta` `( x1, x2)`, we want to create a `97 x 2` matrix that contains the input values on the first column and second column.\n",
    "\n",
    "Notice that unlike in the last class, we did not create a third column here that contains `ones` which are coefficients for the **bias** `ie (theta0)`. This is because we would still have to normalize the input data. and it makes no sense normalizing `ones`, because we want them to remain as `ones`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input values - xs and 1s\n",
    "nrows = data.shape[0]\n",
    "ncols = data.shape[1]\n",
    "\n",
    "x = data.loc[:, ['size','bedroom']].values #converts to Numpy array\n",
    "x = x.reshape(nrows, 2)  # Alternatively x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we want to create a row vector with a dimension of 47 x 1 for all the output values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output variable \n",
    "y = data.loc[:, 'price'].values # convert to Numpy array\n",
    "y = y.reshape(nrows, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/prepro1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance. \n",
    "In this notebook, we will normalize our data using the formula below\n",
    "![title](img/norm.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNorm(x_data):\n",
    "    # save the feature data in another variable\n",
    "    x_norm = x_data.copy()\n",
    "    \n",
    "    # Create a row vector of zeros, having the same number of rows as the input feature\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    x_mean = np.mean(x_data[:, :2], axis = 0)\n",
    "    x_std = np.std(x_data[:, :2], axis = 0)\n",
    "    \n",
    "    print('Mean and std of room sizes: {}: {} respectively'.format(x_mean[0],x_std[0]))\n",
    "    print('Mean and std of bedrooms : {}: {} respectively'.format(x_mean[1],x_std[1]))\n",
    "    \n",
    "    # Using the above formula\n",
    "    x_norm = np.divide((x_data[:, :2] - x_mean), x_std)\n",
    "    \n",
    "    # Insert one vector that represents the coefficient of the bias \n",
    "    x_norm = np.insert(x_norm, 0, 1, axis=1)\n",
    "    print('A ones vector has been successfully concatenated to the input feature matrix')\n",
    "    \n",
    "    return x_norm, x_mean, x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_norm, x_mean, x_std = featureNorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the class, the process to training a linear regression model is as follow.\n",
    "\n",
    "We want to find the appropriate value of `theta` that will give us a good estimate of a city's profit if lthe city's population is supplied.\n",
    "\n",
    "To do this, \n",
    "- We want to start with a random value of `theta` to generate a hypothesis\n",
    "![title](img/model3.gif)\n",
    "\n",
    "- Then continually correct values of `theta` until the deviation of the hypothesis/prediction `h` from the ground-truth `y` is greatly reduced\n",
    "\n",
    "**Note:** In the last class, we used something like this `theta = [[0],[0],[0]]` to initialize the values of theta. Going forward, we will use the numpy function to initialize the values of theta, because we could have large number of theta values. ie `theta = np.zeros(3,1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y, print_every):\n",
    "    #print_every = 40\n",
    "    iteration = 1000\n",
    "    \n",
    "    # For this practice are initiallizing are theta with values of zero.\n",
    "    theta = np.zeros((3,1))\n",
    "    \n",
    "    # Here, want to save our cost function or loss or square error, \n",
    "    # so that we can have an idea of how the deviation of the hypothesis from the ground thruth reduces\n",
    "    cost_function = np.zeros(iteration)\n",
    "    \n",
    "    for i in range(0, iteration):\n",
    "        # Step 1: we make a prediction using the random weights (theta) that we initialized\n",
    "        # @ is a fancy way do performing dot products\n",
    "        h = x @ theta\n",
    "        \n",
    "        # Step 2: We take a step to correct the weights (theta) to that the next predicion will be better\n",
    "        theta = update_weight(h, theta, x)\n",
    "        \n",
    "        # Step 3: We measure the deviation or error\n",
    "        cost_function[i] = cost(x, theta)\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            #print(\"Running Gradient Descent. Iteration: {} cost function: {}\".format(np.log(iteration,cost_function[i]))\n",
    "            print(\"Iteration: {}, Cost function: {} \".format(i, np.log(cost_function[i])))\n",
    "        \n",
    "    return theta, cost_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we check the error like we defined above?\n",
    "\n",
    "Remember the error formular (cost function)? \n",
    "![title](img/model44.gif)\n",
    "\n",
    "where:\n",
    "- `m` is the number of training example\n",
    "- `x` is the input data\n",
    "- `h` is the hypothesis\n",
    "- `y` is the prediction\n",
    "\n",
    "The equation tries to find the square error between the ground truth and the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, theta):\n",
    "    m = x[:,0].size\n",
    "    h = x @ theta\n",
    "    return (1/2*m) * np.sum(np.square(h - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are able to get a sense of the error, how do we update how weight (theta) such that is predicts better?\n",
    "\n",
    "Like we discussed in class, gradient descent algorithim will be used for this purpose.\n",
    "\n",
    "The general formular for gradient is given below:\n",
    "![title](img/model6.gif)\n",
    "which can be differentiated to give:\n",
    "![title](img/model5.gif)\n",
    "where\n",
    "- alpha is the learning rate\n",
    "\n",
    "ie: we continually update the weight(theta) by taking steps(alpha) for the derived gradient of the error until we have sufficiently minimized theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(h, theta, x):\n",
    "    m = x[:,0].size\n",
    "    alpha = 0.01\n",
    "    theta = theta - alpha * (1/m * (x.T @ (h - y)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets pass in our data and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, cost_values = train(x_norm, y, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets see our trained weights\n",
    "print('Our learned value of theta: ',theta.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize how or error reduced during the iteration. This is the power of gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_values)\n",
    "plt.ylabel('Cost J')\n",
    "plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at the `400th iteration`, the model doesnt really change anymore. You should actually stop the iteration at that time and save cost of processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Lets write a predict function that takes in the input features and produces an estimate price for the type of house desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, x_mean, x_std):\n",
    "    input_size = float(input(\"Input the size (square feet) of house you want: \"))\n",
    "    input_bedrooms = float(input(\"Input the number of bedrooms you desire: \"))\n",
    "    print(\"\\n Calculating -- -- -- -- -- -- -- \\n\")\n",
    "    \n",
    "    # input vector\n",
    "    input_vec = np.array([input_size, input_bedrooms])\n",
    "    \n",
    "    #print(input_vec_bias)\n",
    "    \n",
    "    # normalization of input vector\n",
    "    input_norm = np.divide((input_vec -  x_mean), x_std)\n",
    "    \n",
    "     # input vector with bias\n",
    "    input_vec_bias = np.insert(input_norm,0, 1)\n",
    "    \n",
    "    price = input_vec_bias @ theta\n",
    "    print(\"For a house of size {} sqft, with {} bedrooms. The price of estimate is N{}\".format(input_size,input_bedrooms,price[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict(theta, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what ius the effect of varying learning rates in the optimization of our weights?\n",
    "Below, we will plot the effect of different learning on the optimization of theta.\n",
    "\n",
    "Study the code for the next 5 mins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some alpha value\n",
    "alphas = [1,0,0.1,0.012]\n",
    "\n",
    "def update_weight_r(h, theta, x, alpha):\n",
    "    m = x[:,0].size\n",
    "    theta = theta - alpha * (1/m * (x.T @ (h - y)))\n",
    "    return theta\n",
    "\n",
    "def cost_r(x):\n",
    "    J = []\n",
    "    theta = [[0],[0],[0]]\n",
    "    iteration = 400\n",
    "    for i in alphas:\n",
    "        alpha = i\n",
    "        m = x[:,0].size\n",
    "        J_alpha = []\n",
    "        for i in range(iteration):\n",
    "            h = x @ theta\n",
    "            theta = update_weight_r(h, theta, x, alpha)\n",
    "            cost = (1/2*m) * np.sum(np.square(h - y))\n",
    "            J_alpha.append(cost)\n",
    "        # reset theta to zero\n",
    "        theta = [[0],[0],[0]]\n",
    "        J.append(J_alpha)\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pass in the value of x into our function defined above \n",
    "cost_alpha = cost_r(x_norm)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(cost_alpha[0])\n",
    "plt.title('lr= 1')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(cost_alpha[1])\n",
    "plt.title('lr= 0')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(cost_alpha[2])\n",
    "plt.title('lr= 0.1')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(cost_alpha[3])\n",
    "plt.title('lr= 0.01')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Discussion/Assignment:** What did you notice in this plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Normal Equation (Analytical Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta = (X^TX)^{-1}X^T\\vec{y}$$\n",
    "Using this formula does not require any feature scaling, and you will get an exact solution in one calculation: there is no \\loop until convergence\" like in gradient descent.\n",
    "\n",
    "Complete the code in normaleqn.py to use the formula above to calculate $\\theta$. Remember that while you don't need to scale your features, we still need to add a column of 1's to the X matrix to have an intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define the formula in a function\n",
    "def normalEqn(X,y):\n",
    "    return np.dot((np.linalg.inv(np.dot(X.T,X))),np.dot(X.T,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pass in our input values the have not been normalized\n",
    "x_non_norm = n_data = np.insert(data.iloc[:,:2].values,0,1, axis=1)\n",
    "\n",
    "theta_analytical = normalEqn(x_non_norm, y)\n",
    "\n",
    "# Display normal equation's result\n",
    "print ('Theta computed from the normal equations:')\n",
    "print (' %s \\n' % theta_analytical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "def predict_analytical(theta):\n",
    "    input_size = float(input(\"Input the size (square feet) of house you want: \"))\n",
    "    input_bedrooms = float(input(\"Input the number of bedrooms you desire: \"))\n",
    "    print(\"\\nCalculating... ... ... ... ... ...\\n\")\n",
    "    input_vec = np.array([[1, input_size, input_bedrooms]])\n",
    "    \n",
    "    \n",
    "    price = input_vec @ theta\n",
    "    print(\"For a house of size \", input_size, \"sqft, with \", input_bedrooms, \"bedrooms, \\nThe price estimate is N\", price[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_analytical(theta_analytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "\n",
    "1. Use `scikit-learn` to develop a linear regression model using the same dataset in this practice and compare result.\n",
    "2. Explore the internet for an multivariant dataset and use this algorithim to train a linear regression model. Use `scikit-learn` too\n",
    "3. Rewrite the train function such that we pass `'iteration',` and `'alpha'` as arguments.\n",
    "4. What did you observe about the changing the `learning rate`?\n",
    "\n",
    "Assignment is due for submission on `03/10/2019`.\n",
    "\n",
    "Submission link will be posted on the `SLACK CHANNEL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is adopted from [Andrew Ng Machine Learning Course](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
